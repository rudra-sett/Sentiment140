{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhGRKxeNhb0E3Or5vBkpM9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7THkOk7P8yJf"
      },
      "source": [
        "Import things\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lxLXAxt8gf5"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D,MaxPooling1D, Input,Dropout,Flatten,Conv1D\n",
        "from keras.models import Sequential\n",
        "from keras import Model\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds\n",
        "import nltk\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVgqTsAy84-e"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VwmAFjY80q1",
        "outputId": "5acd7527-d89d-485a-8979-83b30e5b042d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "data = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding = \"ISO-8859-1\")\n",
        "data.columns = [\"Target\",\"ID\",\"Date\",\"NO_QUERY\",\"User\",\"Text\"]\n",
        "data = data[['Text','Target']]\n",
        "print(data[ data['Target'] == 0].size)\n",
        "print(data[ data['Target'] == 4].size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1599998\n",
            "1600000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLzspUlT8-5p"
      },
      "source": [
        "Function to clean a given piece of text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv94EokZ87yP"
      },
      "source": [
        "def clean(text):\n",
        "    #very simple text cleaning; simply lowercases and removes punctuation\n",
        "    cleaned = \"\".join(c for c in text if c not in string.punctuation)\n",
        "    return cleaned.lower().replace(\"\\n\", \" \")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bus7I589CvM"
      },
      "source": [
        "data[\"Text\"]=data[\"Text\"].map(clean)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7_na_P99G9w"
      },
      "source": [
        "Tokenize the text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCw7lqTw9L_l"
      },
      "source": [
        "embed_dim = 100\n",
        "seq_length = 300\n",
        "max_features = 100000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(data['Text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['Text'].values)\n",
        "X = pad_sequences(X, padding = \"post\",truncating=\"post\",maxlen = seq_length)\n",
        "Y = data[\"Target\"].values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7TTSltof6IH"
      },
      "source": [
        "Y = data[\"Target\"].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ywIe47qgOBH",
        "outputId": "691b3c50-43e6-4bf0-8ced-93562fdcaf27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wt2VFtL3bE9"
      },
      "source": [
        "Y = Y/4"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs2KxpTH26Ne",
        "outputId": "ff62a6ee-028a-4e64-d2da-b3f47c8f694f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.unique(Y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU7wV1QL9P4T"
      },
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc2z7qHtJC8_",
        "outputId": "6a67b72b-5ee5-4ad1-d2b8-b4277ca9eb5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embed_dim"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU0auMqs9RPw",
        "outputId": "ffa9c8fe-cac5-4c6a-a0a4-922e9341afe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "source": [
        "inputs1 = Input(shape=(seq_length,))\n",
        "embedding1 = Embedding(max_features, embed_dim,input_length=seq_length)(inputs1)\n",
        "conv1 = Conv1D(filters=64, kernel_size=2,padding=\"same\")(embedding1)\n",
        "maxpool1 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
        "#flat1 = Flatten()(maxpool1)\n",
        "\n",
        "conv2 = Conv1D(filters=64, kernel_size=4,padding=\"same\")(embedding1)\n",
        "maxpool2 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv2)\n",
        "#flat2 = Flatten()(maxpool2)\n",
        "\n",
        "conv3 = Conv1D(filters=64, kernel_size=6,padding=\"same\")(embedding1)\n",
        "maxpool3 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv3)\n",
        "#flat3 = Flatten()(maxpool3)\n",
        "\n",
        "conv4 = Conv1D(filters=64, kernel_size=8,padding=\"same\")(embedding1)\n",
        "maxpool4 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv4)\n",
        "#flat4 = Flatten()(maxpool4)\n",
        "\n",
        "print(maxpool1.shape)\n",
        "#drop1 = Dropout(0.2)(conv1)\n",
        "#pool1 = tf.keras.layers.GlobalAveragePooling1D()(conv1)\n",
        "#pool2 = tf.keras.layers.GlobalAveragePooling1D()(conv2)\n",
        "#pool3 = tf.keras.layers.GlobalAveragePooling1D()(conv3)\n",
        "#pool4 = tf.keras.layers.GlobalAveragePooling1D()(conv4)\n",
        "concat = tf.keras.layers.Concatenate()([maxpool1,maxpool2,maxpool3,maxpool4])\n",
        "flat1 = tf.keras.layers.glo\n",
        "dropout1 = Dropout(0.2)(concat)\n",
        "x = Dense(1024, activation='relu')(dropout1)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(4, activation = \"relu\")(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "model = Model(inputs=inputs1, outputs=outputs)\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 150, 64)\n",
            "Model: \"functional_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 300)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_14 (Embedding)        (None, 300, 100)     10000000    input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_56 (Conv1D)              (None, 300, 64)      12864       embedding_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_57 (Conv1D)              (None, 300, 64)      25664       embedding_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_58 (Conv1D)              (None, 300, 64)      38464       embedding_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_59 (Conv1D)              (None, 300, 64)      51264       embedding_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_56 (MaxPooling1D) (None, 150, 64)      0           conv1d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_57 (MaxPooling1D) (None, 150, 64)      0           conv1d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_58 (MaxPooling1D) (None, 150, 64)      0           conv1d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_59 (MaxPooling1D) (None, 150, 64)      0           conv1d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 150, 256)     0           max_pooling1d_56[0][0]           \n",
            "                                                                 max_pooling1d_57[0][0]           \n",
            "                                                                 max_pooling1d_58[0][0]           \n",
            "                                                                 max_pooling1d_59[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 150, 256)     0           concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 150, 1024)    263168      dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 150, 1024)    0           dense_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 150, 4)       4100        dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 150, 4)       0           dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 150, 2)       10          dropout_41[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 10,395,534\n",
            "Trainable params: 10,395,534\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnPAvcCdeY5J"
      },
      "source": [
        "model."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Us8WLSb9V1Y"
      },
      "source": [
        "Split the data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygz158qV9Xne"
      },
      "source": [
        "# Define a size for train set\n",
        "train_size = int(0.6 * len(X))\n",
        "# Split dataset \n",
        "train_X = X[:train_size]\n",
        "test_X = X[train_size:]\n",
        "train_Y = Y[:train_size]\n",
        "test_Y = Y[train_size:]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O3TzxF09cfj"
      },
      "source": [
        "Aaaand... start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH77FO119a2s",
        "outputId": "1d9feecb-ecf6-44db-bc23-dc5e997c9391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "batch_size = 200\n",
        "model.fit(train_X, train_Y, epochs = 3, batch_size=batch_size,validation_data=(test_X,test_Y))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "4800/4800 [==============================] - ETA: 0s - loss: 0.3131 - accuracy: 0.8767WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_test_batch_end` time: 0.0127s). Check your callbacks.\n",
            "4800/4800 [==============================] - 808s 168ms/step - loss: 0.3131 - accuracy: 0.8767 - val_loss: 1.1012 - val_accuracy: 0.4373\n",
            "Epoch 2/3\n",
            "4800/4800 [==============================] - 801s 167ms/step - loss: 0.2591 - accuracy: 0.8977 - val_loss: 1.3723 - val_accuracy: 0.3414\n",
            "Epoch 3/3\n",
            "4800/4800 [==============================] - 800s 167ms/step - loss: 0.2199 - accuracy: 0.9143 - val_loss: 1.5089 - val_accuracy: 0.4705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74b4159668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6uxItzY9gs5"
      },
      "source": [
        "Test the model on a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnPPcOEy9lyu",
        "outputId": "18178c21-ce15-4189-fa33-88a9b028b94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "validation_size = 10000\n",
        "X_validate = test_X[-validation_size:]\n",
        "Y_validate = test_Y[-validation_size:]\n",
        "# X_test = X_test[:-validation_size]\n",
        "# Y_test = Y_test[:-validation_size]\n",
        "score,acc = model.evaluate(test_X, test_Y, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 325/3200 [==>...........................] - ETA: 57s - loss: 1.6822 - accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b97569931039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X_test = X_test[:-validation_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Y_test = Y_test[:-validation_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFVfLT6D9ptR"
      },
      "source": [
        "Function to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr0GUetq9uig"
      },
      "source": [
        "def guess(twt):\n",
        "    #vectorizing the tweet by the pre-fitted tokenizer instance\n",
        "    twt = [twt]\n",
        "    twt = tokenizer.texts_to_sequences(twt)\n",
        "    #padding the tweet to have exactly the same shape as `embedding_2` input\n",
        "    twt = pad_sequences(twt, maxlen=seq_length, dtype='int32', value=0)\n",
        "    sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
        "    #print(sentiment)\n",
        "    print(\"Confidence: \" + str(sentiment[np.argmax(sentiment)]*100) + \"%\")\n",
        "    if(np.argmax(sentiment) == 0):\n",
        "        print(\"negative\")\n",
        "    elif (np.argmax(sentiment) == 1):\n",
        "        print(\"positive\")\n",
        "    elif (np.argmax(sentiment) == 2):\n",
        "        print(\"neutral\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsH69Vrk-3PB",
        "outputId": "0d0e50f4-29ec-4fb5-f041-60f5f8f7543e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "guess(\"Tesla batteries are very safe\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s\n",
            "Confidence: 82.65024423599243%\n",
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfHUANM7DAtX"
      },
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}